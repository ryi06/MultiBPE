import argparse
import os
import pickle
import time
from subprocess import check_call

import numpy as np
from tqdm import tqdm

import pybedtools
from utils import (
    FeatureWriter,
    Sample,
    SignalNormalizer,
    display_args,
    print_time,
)

parser = argparse.ArgumentParser(
    "Retrieve cell type feature signals for sample sequences."
)

parser.add_argument("metadata_pkl", type=str, help="Path to example .pkl file.")
parser.add_argument("peak_file", type=str, help="Feature peak bed file.")
parser.add_argument("bigWig_file", type=str, help="Feature signal bigWig file.")
parser.add_argument("assay_type", type=str, help="Assay type")
parser.add_argument("cell_type", type=str, help="Name of the cell type.")
parser.add_argument(
    "zscore_folder", type=str, help="Output zscore params file path."
)
parser.add_argument(
    "--sequence_length", type=int, default=1000, help="Sample sequence length."
)
parser.add_argument(
    "--batch_size", type=int, default=10000, help="Data file batch size."
)
parser.add_argument(
    "--tmp_dir", type=str, default=".", help="Path to temp directory."
)

args = parser.parse_args()
display_args(args, __file__)

############## FUNCTION ##############
def retrieve_signal(
    peak_file, bigWig_file, seq_dict, tmp_file, group_name, assay_type
):
    peaks = pybedtools.BedTool(peak_file)
    num_samples = len(seq_dict["input"])
    writer = FeatureWriter(
        args.batch_size,
        args.sequence_length,
        num_samples,
        group_name,
        assay_type,
    )

    for k in tqdm(seq_dict["input"].keys()):
        # Initialize signal track.
        signal = np.zeros(args.sequence_length)

        # Construct BedTool input from sample sequence location.
        sample = Sample(seq_dict["input"][k])
        entry = "{} {} {}".format(sample.chrom, sample.start, sample.stop)
        a = pybedtools.BedTool(entry, from_string=True)

        # Retrieve sample bigwig signal that fall within peak regions.
        apeaks = a.intersect(peaks)
        for p in apeaks:
            cmd = "bigWigToBedGraph -chrom={} -start={} -end={} {} {}".format(
                sample.chrom, p.start, p.stop, bigWig_file, tmp_file
            )
            check_call(cmd, shell=True)
            with open(tmp_file, "rb") as wigs:
                for line in wigs:
                    record = line.strip().decode("utf-8").split("\t")
                    s = int(record[1]) - sample.start
                    t = int(record[2]) - sample.start
                    signal[s:t] = float(record[3])
        # Write signal track to disk.
        writer.write_feature(
            signal, k, seq_dict["input"][k][assay_type][group_name]
        )
        # Clean up tmp files generated by pybedtools.
        if (k + 1) % 1000 == 0:
            pybedtools.cleanup(remove_all=True)
    return writer


def merge_signal(writer, seq_length):
    original = np.empty((writer.counter, seq_length))
    original[:] = np.NaN
    for path in writer.paths:
        batch = np.load(path)
        print_time("[{}:{}]".format(batch["start"], batch["stop"]), start_time)
        original[batch["start"] : batch["stop"]] = batch["original"]
    return original


def zscore_signal(writer, original, save_params):
    # Retrieve/generate zscore params
    if os.path.isfile(save_params):
        params = np.load(save_params)
        normalizer = SignalNormalizer(
            "zscore", mu=params["mu"], std=params["std"]
        )

    else:
        mu = np.mean(original)
        std = np.std(original)
        normalizer = SignalNormalizer(
            "zscore", save_params=save_params, mu=mu, std=std
        )
    print_time(
        "mu={:.4f}, std={:.4f} obtained from {}".format(
            normalizer.mu, normalizer.std, save_params
        ),
        start_time,
    )
    zscore = normalizer.normalize(original)

    # Save zscored signal to disk.
    for path in writer.paths:
        batch = dict(np.load(path))
        batch["zscore"] = zscore[batch["start"] : batch["stop"]]
        np.savez_compressed(path, **batch)


############## MAIN ##############
seq_dict = pickle.load(open(args.metadata_pkl, "rb"))
start_time = time.time()

print_time("Getting original feature signal", start_time)
tmp_wig = os.path.join(args.tmp_dir, "tmp.wig")
signal_writer = retrieve_signal(
    args.peak_file,
    args.bigWig_file,
    seq_dict,
    tmp_wig,
    args.cell_type,
    args.assay_type,
)

print_time("Merging original data", start_time)
original_data = merge_signal(signal_writer, args.sequence_length)

print_time("Normalizing feature signal", start_time)
zscore_file = os.path.join(
    args.zscore_folder,
    "{}.{}.zscore_params.npz".format(args.assay_type, args.cell_type),
)
zscore_signal(signal_writer, original_data, zscore_file)

print_time("All samples processed!", start_time)
